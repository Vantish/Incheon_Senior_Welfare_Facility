import streamlit as st
from google import genai
from app_around_leisure_restaurant import around_restaurant
from app_location import run_location
import pandas as pd

df = pd.read_csv('./data/ì¸ì²œì‹ë‹¹_ì¹´í…Œê³ ë¦¬_ìˆ˜ì •.csv',encoding='euc-kr')

st.set_page_config(page_title="Gemini Chat", page_icon="ğŸ¤–")

LLM_MODEL = "gemini-2.5-flash"  # ëª¨ë¸ëª… ì§€ì •


def _init_session():
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
        ]


def _get_client():
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key:
        return None
    return genai.Client(api_key=api_key)


def _generate_reply(client, model, prompt):
    response = client.models.generate_content(
        model=model,
        contents=prompt,
    )
    return getattr(response, "text", str(response))


def main():
    _init_session()

    st.title("ì‚¬ìš©ì ê·¼ì²˜ì˜ ì‹ë‹¹ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤")
    st.subheader("ì°¾ì•„ë³´ê³  ì‹¶ì€ ì‹ë‹¹ ë˜ëŠ” ìŒì‹ì„ ë§ì”€í•´ì£¼ì„¸ìš” :")

    client = _get_client()
    if client is None:
        st.error("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Streamlit secretsì— GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        st.info("ì„¤ì • ì˜ˆ: .streamlit/secrets.toml ì— `GEMINI_API_KEY = \"your_api_key\"` ì¶”ê°€")
        return

    for msg in st.session_state.messages:
        if msg["role"] == "user":
            st.chat_message("user").write(msg["content"])
        else:
            st.chat_message("assistant").write(msg["content"])

    # ì‚¬ì´ë“œë°”: ìœ„ì¹˜ ì…ë ¥(ë„ë¡œëª… ì£¼ì†Œ)ì„ ë°›ì•„ ì„¸ì…˜ì— ì €ì¥
    with st.sidebar.expander('ë‚´ ìœ„ì¹˜(ë„ë¡œëª… ì£¼ì†Œ) ì…ë ¥'):
        loc = run_location()
        if loc is not None:
            st.session_state['user_location'] = loc
            st.success('ìœ„ì¹˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë©”ì¸ ì°½ì—ì„œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.')

    user_input = st.chat_input("ì—¬ê¸°ì— ì…ë ¥í•´ì£¼ì„¸ìš” ")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})

        # ê°„ë‹¨í•œ ìŒì‹/ì‹ë‹¹ ì¶”ì²œ ì˜ë„ íŒë‹¨
        def looks_like_food_request(text: str) -> bool:
            t = text.lower()
            food_keywords = ['ì¹˜í‚¨','í•œì‹','ì¤‘ì‹','ì§œì¥','ì§¬ë½•','í”¼ì','ì´ˆë°¥','ì¼ì‹','ì¡±ë°œ','ë³´ìŒˆ','ì¹¼êµ­ìˆ˜','ë¶„ì‹','í–„ë²„ê±°','ì¹´í˜','ì»¤í”¼','ì‹ë‹¹','ë§›ì§‘']
            if 'ì¶”ì²œ' in t or 'ë¨¹ê³ ' in t or 'ë¨¹ê³ ì‹¶' in t:
                return True
            for kw in food_keywords:
                if kw in t:
                    return True
            return False

        if looks_like_food_request(user_input):
            user_loc = st.session_state.get('user_location')
            if not user_loc:
                assistant_text = 'ë§›ì§‘ ì¶”ì²œì„ ìœ„í•´ ì‚¬ì´ë“œë°”ì—ì„œ ë„ë¡œëª… ì£¼ì†Œë¥¼ ì…ë ¥í•˜ê³  ì…ë ¥ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìœ„ì¹˜ë¥¼ ì €ì¥í•´ ì£¼ì„¸ìš”.'
                st.session_state.messages.append({"role": "assistant", "content": assistant_text})
                st.rerun()

            # user_loc expected [lat, lon, address, selected_type]
            latlon = (user_loc[0], user_loc[1])
            df_rec = around_restaurant(latlon)
            if df_rec is None or df_rec.empty:
                assistant_text = 'í•´ë‹¹ ìœ„ì¹˜ ì£¼ë³€ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì‹ë‹¹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'
                st.session_state.messages.append({"role": "assistant", "content": assistant_text})
                st.rerun()

            # build context list from df_rec (limit to 20 rows)
            lines = []
            for i, row in df_rec.head(20).iterrows():
                name = row.get('ìƒí˜¸','')
                addr = row.get('ë„ë¡œëª… ì£¼ì†Œ','')
                dist = row.get('ê±°ë¦¬(km)')
                dist_text = f"{dist:.2f}km" if pd.notna(dist) else ''
                lines.append(f"[{i+1}] {name} / {addr} / {dist_text}")

            context_text = "\n".join(lines)

            # instruct LLM to answer using only this list
            system_instruction = (
                "ì•„ë˜ ì œê³µëœ ì‹ë‹¹ ëª©ë¡ ì •ë³´ë§Œì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n"
                "ëª©ë¡ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  'ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.\n"
            )
            prompt = system_instruction + "\nì‹ë‹¹ ëª©ë¡:\n" + context_text + "\n\nì§ˆë¬¸: " + user_input

            with st.spinner('ì¶”ì²œ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„± ì¤‘...'):
                try:
                    reply_text = _generate_reply(client, LLM_MODEL, prompt)
                except Exception as e:
                    reply_text = f'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}'

            st.session_state.messages.append({"role": "assistant", "content": reply_text})
            st.rerun()

        system_instruction = (
            "ë‹¹ì‹ ì€ ì–´ë¥´ì‹ (ë…¸ë…„ì¸µ)ì„ ëŒ€ìƒìœ¼ë¡œ ìƒëƒ¥í•˜ê³  ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì‘ë‹µí•˜ëŠ” ìƒë‹´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
            "ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , ì²œì²œíˆ, ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”. ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ì–´ ì„¤ëª…í•˜ê³ , "
            "í•œ ë²ˆì— í•œ ê°€ì§€ ì •ë³´ë¥¼ ì œê³µí•˜ë©° ë°°ë ¤ì‹¬ ìˆê³  ê³µì†í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."
            "ë‹µë³€í• ë•Œ ì–´ë¥´ì‹  ë³´ë‹¤ëŠ” ì‚¬ìš©ìë‹˜ ì„ ì“°ë˜ ì¹œê·¼í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”."
            "ê²€ìƒ‰ ì§€ì—­ì€ 'ì¸ì²œ' ìœ¼ë¡œ í•œì •í•©ë‹ˆë‹¤"
        )
        conversation_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])
        prompt = system_instruction + "\n\n" + conversation_text

        with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
            try:
                reply_text = _generate_reply(client, LLM_MODEL, prompt)
            except Exception as e:
                reply_text = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

        st.session_state.messages.append({"role": "assistant", "content": reply_text})
        st.rerun()


if __name__ == '__main__':
    main()